{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current directory\n",
    "import os\n",
    "os.chdir('F:\\Work\\Experiment\\pLM4ACE\\model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import pandas as pd\n",
    "\n",
    "X_new = pd.read_csv(r\"fusion_features\\Data\\features_select\\mRMR_All_100.csv\", index_col=False, header=None)\n",
    "y_new = loadtxt('fusion_features\\Data\\label.csv', delimiter=',')\n",
    "\n",
    "print(X_new.shape)\n",
    "print(y_new.shape)\n",
    "print(np.count_nonzero(y_new==0))\n",
    "print(np.count_nonzero(y_new==1))\n",
    "\n",
    "X_new = np.array(X_new)\n",
    "y_new = np.array(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# 数据预处理\n",
    "scaler = StandardScaler()\n",
    "X_new = scaler.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 寻找最佳参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# dataset splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_whole, X_ind_test, y_train_whole, y_ind_test =  train_test_split( X_new, y_new, test_size=0.2, random_state=1111)\n",
    "\n",
    "print(X_train_whole.shape)\n",
    "print(X_ind_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_cv_mean_collection = []\n",
    "C = [0.001, 0.01, 0.1,  0.5, 1.1, 1.3, 5, 10, 30, 50, 100, 300]\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "degree = [1, 3, 5, 7, 9]\n",
    "tol = [1e-5]\n",
    "for i in C:\n",
    "    for j in kernel:\n",
    "        for k in degree:\n",
    "            for p in tol:\n",
    "                acc_cv_collection = []\n",
    "                clf = SVC(C=i, kernel=j, degree=k)  # need to tune the hyperparameters\n",
    "                from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "                skf = StratifiedKFold(n_splits=10)\n",
    "                for train, test in skf.split(X_train_whole, y_train_whole):\n",
    "                    X_train, X_valid, y_train, y_valid = np.take(X_train_whole, train.tolist(), axis=0), np.take(X_train_whole,\n",
    "                                                                                                                test.tolist(),\n",
    "                                                                                                                axis=0), np.take(\n",
    "                        y_train_whole, train.tolist(), axis=0), np.take(y_train_whole, test.tolist(), axis=0)\n",
    "                    clf.fit(X_train, y_train)\n",
    "                    y_valid_pred = clf.predict(X_valid)\n",
    "                    acc_cv = balanced_accuracy_score(y_valid, y_valid_pred)\n",
    "                    acc_cv_collection.append(acc_cv)\n",
    "                acc_cv_mean_collection.append(round(statistics.mean(acc_cv_collection),3))\n",
    "                print(clf,round(statistics.mean(acc_cv_collection),3), round(statistics.stdev(acc_cv_collection),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10折交叉验证测试\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_whole, X_ind_test, y_train_whole, y_ind_test =  train_test_split( X_new, y_new, test_size=0.2, random_state=1111)\n",
    "\n",
    "BACC_collecton = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "AUC_collecton = []\n",
    "AP=[]\n",
    "mean_recall = np.linspace(0, 1, 100)\n",
    "all_precision = []\n",
    "base_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = 0.0\n",
    "# 新的TPR集合\n",
    "interp_tpr_collection = []\n",
    "\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "# model\n",
    "clf = SVC(C=5, degree=1, probability=True)  # need to tune the hyperparameters\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "for train, test in skf.split(X_train_whole, y_train_whole):\n",
    "    X_train, X_valid, y_train, y_valid = np.take(X_train_whole, train.tolist(), axis=0), np.take(X_train_whole,\n",
    "                                                                                                    test.tolist(),\n",
    "                                                                                                    axis=0), np.take(\n",
    "        y_train_whole, train.tolist(), axis=0), np.take(y_train_whole, test.tolist(), axis=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # 将预测结果转化为概率\n",
    "    y_pred_proba = clf.predict_proba(X_valid) # 获取正类别的概率\n",
    "    y_valid_pred = categorical_probas_to_classes(y_pred_proba)\n",
    "    TP, FP, FN, TN = confusion_matrix(y_valid, y_valid_pred).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "    Sn_collecton.append(TP/(TP+FN))\n",
    "    Sp_collecton.append(TN/(TN+FP))\n",
    "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "    MCC_collecton.append(MCC)\n",
    "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
    "    auc = roc_auc_score(y_valid, y_pred_proba[:, 1])\n",
    "    AUC_collecton.append(auc)\n",
    "    # ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_valid, y_pred_proba[:, 1])\n",
    "    interp_tpr = np.interp(base_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    interp_tpr_collection.append(interp_tpr)\n",
    "    # PR curve\n",
    "    precision, recall, _ = precision_recall_curve(y_valid, y_pred_proba[:, 1])\n",
    "    average_precision = average_precision_score(y_valid, y_pred_proba[:, 1])\n",
    "    recall = np.flipud(recall)\n",
    "    precision = np.flipud(precision)\n",
    "\n",
    "    mean_precision = np.interp(mean_recall, recall, precision)\n",
    "    all_precision.append(mean_precision)\n",
    "    AP.append(average_precision)\n",
    "\n",
    "# 输出结果\n",
    "print(round(statistics.mean(BACC_collecton),3),'±',round(statistics.stdev(BACC_collecton),3))\n",
    "print(round(statistics.mean(Sn_collecton),3),'±',round(statistics.stdev(Sn_collecton),3))\n",
    "print(round(statistics.mean(Sp_collecton),3),'±',round(statistics.stdev(Sp_collecton),3))\n",
    "print(round(statistics.mean(MCC_collecton),3),'±',round(statistics.stdev(MCC_collecton),3))\n",
    "print(round(statistics.mean(AUC_collecton),3),'±',round(statistics.stdev(AUC_collecton),3))\n",
    "print(round(statistics.mean(AP),3),'±',round(statistics.stdev(AP),3))\n",
    "\n",
    "# 在所有交叉验证循环结束后，计算TPR的均值\n",
    "mean_tpr = np.mean(interp_tpr_collection, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "\n",
    "# Calculate the mean precision\n",
    "mean_precision = np.mean(all_precision, axis=0)\n",
    "\n",
    "# # 保存ROC曲线相关参数\n",
    "# np.savez(r'Draw graphics\\ROC curve\\PCA_All\\SVM_cross_vaild.npz', fpr=base_fpr, tpr=mean_tpr, roc_auc=AUC_collecton)\n",
    "\n",
    "# # 保存PR曲线相关参数\n",
    "# np.savez(r'Draw graphics\\PR curve\\PCA_All\\SVM_cross_vaild.npz', recall=mean_recall, precision=mean_precision, average_precision=AP)\n",
    "\n",
    "# 绘制ROC曲线\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(base_fpr, mean_tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % np.mean(AUC_collecton))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('10 k-fold cross vaild')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 独立测试集\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# result collection list\n",
    "BACC_collecton = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "AUC_collecton = []\n",
    "AP=[]\n",
    "mean_recall = np.linspace(0, 1, 100)\n",
    "all_precision = []\n",
    "base_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = 0.0\n",
    "# 新的TPR集合\n",
    "interp_tpr_collection = []\n",
    "\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "for i in range(10):\n",
    "    # dataset splitting\n",
    "    X_train_whole, X_ind_test, y_train_whole, y_ind_test =  train_test_split(X_new, y_new, test_size=0.2, random_state=i)\n",
    "    clf = SVC(C=5, degree=1, probability=True)  # need to tune the hyperparameters\n",
    "    clf.fit(X_train_whole,y_train_whole)# fitting model \n",
    "    # 获得预测得分\n",
    "    y_pred_score = clf.predict_proba(X_ind_test)\n",
    "    y_pred = categorical_probas_to_classes(y_pred_score)    # predict results\n",
    "    y_true = y_ind_test                 # asign values for confusiong matrix calculation\n",
    "    TP, FP, FN, TN = confusion_matrix(y_true, y_pred).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "    Sn_collecton.append(TP/(TP+FN))\n",
    "    Sp_collecton.append(TN/(TN+FP))\n",
    "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "    MCC_collecton.append(MCC)\n",
    "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
    "    auc = roc_auc_score(y_true, y_pred_score[:, 1])\n",
    "    AUC_collecton.append(auc)\n",
    "    # ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_score[:, 1])\n",
    "    interp_tpr = np.interp(base_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    interp_tpr_collection.append(interp_tpr)\n",
    "    # PR curve\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred_score[:, 1])\n",
    "    average_precision = average_precision_score(y_true, y_pred_score[:, 1])\n",
    "    recall = np.flipud(recall)\n",
    "    precision = np.flipud(precision)\n",
    "\n",
    "    mean_precision = np.interp(mean_recall, recall, precision)\n",
    "    all_precision.append(mean_precision)\n",
    "    AP.append(average_precision)\n",
    "    \n",
    "print(round(statistics.mean(BACC_collecton),3),'±',round(statistics.stdev(BACC_collecton),3))\n",
    "print(round(statistics.mean(Sn_collecton),3),'±',round(statistics.stdev(Sn_collecton),3))\n",
    "print(round(statistics.mean(Sp_collecton),3),'±',round(statistics.stdev(Sp_collecton),3))\n",
    "print(round(statistics.mean(MCC_collecton),3),'±',round(statistics.stdev(MCC_collecton),3))\n",
    "print(round(statistics.mean(AUC_collecton),3),'±',round(statistics.stdev(AUC_collecton),3))\n",
    "print(round(statistics.mean(AP),3),'±',round(statistics.stdev(AP),3))\n",
    "\n",
    "# 在所有交叉验证循环结束后，计算TPR的均值\n",
    "mean_tpr = np.mean(interp_tpr_collection, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "\n",
    "# Calculate the mean precision\n",
    "mean_precision = np.mean(all_precision, axis=0)\n",
    "\n",
    "# # 保存ROC曲线相关参数\n",
    "# np.savez(r'Draw graphics\\ROC curve\\PCA_All\\SVM_Indenpendence.npz', fpr=base_fpr, tpr=mean_tpr, roc_auc=AUC_collecton)\n",
    "\n",
    "# # 保存PR曲线相关参数\n",
    "# np.savez(r'Draw graphics\\PR curve\\PCA_All\\SVM_Indenpendence.npz', recall=mean_recall, precision=mean_precision, average_precision=AP)\n",
    "\n",
    "# 绘制ROC曲线\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(base_fpr, mean_tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % np.mean(AUC_collecton))\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Independence test')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
